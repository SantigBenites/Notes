# Perceptron

The perceptron is a computational interpretation of natures neuron. 
It works as the building block of learning models.
It works by receiving stimuli and firing an output based on the stimuli/

## Essential Learning Procedure

The process by which perceptron's learns bases itself on a binary classifier.
This is a function that given a certain entry $x$ and certain weights for the elements of the entry $w$ calculates a value $$g(z) = x_1 * w_1 + \dots + x_n*w_n$$ if this value of $g(z)>0$ then it outputs 1, if else it outputs -1, this will be the input of the activation function.
We take this expected outcome and compare it to the expected value, after this based on if the model is correct or not, the weights of the model will be altered to fit whatever the model is trying to achieve.
Lastly when updating the weights we use the formula $$w_{t+1} = w_t + r*(desiredOutput - realOutput)*x$$
Where r is going to be the learning rate of the model.
Too large of a learning rate and the model will diverge
Too small and we can get a suboptimal solution
The activation function will be the last step of the perceptron, and it will give out the output, multiple can be used
- Sigmoid - Exactly the same as Logistic Regression!
- Linear
- Logistic
- Hyperbolic

## Adaptive Linear Neurons (Adaline)

The previous process even thought revolutionary, had several problems such as having trouble when the classes of the problem couldn't be separated linearly.
This lead to invention of Adaline, Adaline added another step to the model, in this case it took the output of the activation function and used it to improve the values of the weights in combination with the previous weight function.

This although didn't allow us to solve the problem of not being able to solve non-linearly separable problems

## Gradient Descent

The gradient descent is instead used when there is non-linear separability among the data set and the output is not thresholded, but continuous.
In this case we have an “activation function” (“_a_”); we have an error which is defined as the sum of the squared values of the difference between the target and the activation. We then try to minimize this error by applying the derivative of it over the weights.

The formulas can be found in the slides...

## Stochastic Gradient Descent

Taking these 2 improvements and combining them, we get Stochastic Gradient Descent, where the goal is to update weights after every run of the activation function, and combining this with gradient descent.
This allows us to
- Improve efficiency
- Update the model with new data
- But makes it so that the results are dependant on data ordering

## Summary
The perceptron is
- simple - takes the same number of parameters as the number of features
- not stable - only stable if the data is linearly separable, otherwise it is very dependant on data order
- fast to learn - Either perceptron or gradient descent are very fast even with big datasets
- fast to make predictions - Uses very simple operations(sum and multiplication)
- Updatable - Can easily accommodate new data without refitting

# MLP (Multilayer Perceptron Neural Network)

While the perceptron is simple, the real juice comes from the combination of multiple perceptron's into neural networks, in these we combine multiple perceptron independently from each other in a network.
In these, we can use perceptron's output as inputs for other perceptron's, making it so that that we structure the network into layers.
![[neuralNetwork.png|500x300]]
Each layers connections will have their own weights to adjust, and will have to account for their own bias
The learning algorithm for this new type of model is called backpropagation.

## Backpropagation

We start by inputting some values through the entry nodes $[x_1,x_2,x_3]$
We then use the real weights to calculate the values of the rest of the network
We get the outputs of every neuron in the network, be it from input layer, hidden layer our output layer
Calculate the error in the output layer $[y_1,y_2]$ using the formula
$$ error = actualValue - desiredValue$$
Travel back from the output layer to the hidden layer to adjust the weights such that the error is decreased.
Keep doing this process until the output layer gives the desired output.

## Final procedure

The training procedure 
- Initialize all the weights with small random values $[-1.0, 1.0]$
- Run a batch of data through the network 
- Update the weights through backpropagation 
- Repeat steps 2-3 until a number of Epochs have occurred or the weights converge and do not change

## Summary

MLP's are very powerful, and dependant on which types of functions they are using as activation function in the perceptions.
Moreover, they require us to know the architecture of the network a priori 

MLP's are
- not simple - normally they are really complex, and difficult to understand
- not stable - they are highly dependant on the order of the data considering they are dependant on perceptron's
- not fast to learn -  they are very demanding on CPU, but can be parallelized to GPU
- fast-ish to make predictions - depends on the size of the network
- updatable - similar to the perceptron's they can easily receive more data