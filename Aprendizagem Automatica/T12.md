# Supervised Learning vs Unsupervised Learning

So far we have been analysing methods related to [[T02#Supervised Learning]], now we will be analysing an unsupervised learning method.

## Supervised Learning

Can be defined as a group of algorithms in which we analyse labelled data, these algorithms "supervise" data and then try to make predictions about its outcome.
Usually these predictions can be classifications or regressions.

## Unsupervised Learning

A group of algorithms which use machine learning to analyse and cluster unlabelled data with the intent of finding hidden patterns without the need for human intervention, therefore "unsupervised"

# Clustering

Clustering is the process of aggregation of physical or abstract objects. These objects are usually aggregated by features they have in common.
The main purpose of clustering is to assume general properties of a cluster for later use.

Clustering is not an easy problem, it is usually considered NP hard.
Moreover, clustering is highly dependant on its parameters, more specifically data and algorithm.

There are 2 main clustering algorithms 

## K-Means

We should use this algorithm when our data is a vector space.
The simplest and most fundamental version of cluster analysis is partitioning, which organizes the objects of a set into several exclusive groups or clusters.

This algorithms woks as follows:
- Choose k objects from the dataset, as initial cluster centres
- Assign each object of the dataset to the centre most similar
- Recalculate the cluster centres
- If the recalculation altered the centers then return to 2nd step else end the algorithm

## Hierarchical Clustering

We can use this algorithm  when our data is a vector space of metric space

A hierarchical clustering method works by grouping data objects into a hierarchy or “tree” of clusters.
There are 2 main types of hierarchical clustering
- Agglomerative- Start with individuals and group them into clusters
- Divisive - Start with a single cluster and divide it into smaller clusters
This allows for the user to specify the number of final clusters

The algorithm works as follows:
- Put each point into a separate cluster
- Compute distance matrix
- Find the closest pair of clusters
- Merge the clusters
- update the clusters
- Update distance matrix
- repeat last 4 step until the number of clusters is the desired number or there are no more clusters

To process how to calculate the distance between clusters we should use some of the distance calculating methods
- Single linkage
- Complete Linkage
- Average Linkage
- Mean Distance
- 