# Machine Learning for Anomaly Detection

Anomalies are defined as events that are different from expected event patterns
Anomalies can means that an attack is taking place, so anomaly detection is essential to detect intrusions

# Anomaly Detection

As indicated previously to detect an anomaly we must make use of a baseline to which to compare an anomalous state.
Without a normal behaviour state, it is impossible to detect abnormal behaviour.
The biggest challenge will be to define what constitutes an abnormal behaviour in comparison to a normal behaviour and where to draw the order between these two.
Take into account that border don't need to be clear margins and are more blurry than that.

## Making an Anomaly Detector

To make a decent anomaly detector it is paramount that we make usage of previously sorted datasets, that specifically classify entries into intrusion or not intrusion

### Challenges
Some of the main challenges stem from the data we are receiving from the system:
- Big datasets - Using millions of entries per day lead to exponential resource requirements
- Dimensionality - Curse of Dimensionality all over again
- Temporal Data - The order of the events might be needed to understand context
- Unbalanced Classes - The rarity of anomalies is a factor to take into account
- Real-Time detection - How to detect problems in real-time before they are damaging

### Types of Learning

As we already know there are 3 main types of learning in machine learning
- Supervised - The input is mapped, for x input we have y output and try to find a correlation between input and output
- Unsupervised - The input isn't mapped, for x input we try to find patterns with the intent of getting a general idea of what is happening
- Semi-supervised - Parts of the output are mapped and others aren't
Our Anomaly detectors usually fall into the last category

### Building or Anomaly Detector (Steps)

The process
1. Monitor the environment where the anomaly detector will reside and create a database with all the events that happen classified (This will create our baseline)
2. Use the database to create a training set, this process will need some data analysis and processing techniques
3. Use the training set to train an anomaly detector (train our classifier), in this step we can use a validation set to validate if the model is accurate (this is optional and done iteratively to detect if we are going in the right direction)
4. Use a test dateset to determine if the model is accurate
![[Anomaly Detectors in Production.png|700]]

### Pre-Processing

The Pre-Processing of the data to be used in training set is essential.
This process consist of activities like:
- Assigning labels to features
- Normalising values
- Remove outliers
This then lead to the separation of Training set and validation set with a normal size 2/3 and 1/3 of the original set respectively.

### Feature Selection

Our datasets will have multiple columns/variables these are called features, it is essential to select the most valid ones to use when training our model.
Therefore the question which features should be used is essential when trying to train our model.

One can ask why not use all features, there are several reasons:
- The complexity and performance of the model would increase exponentially
- Simpler models are more robust
- Some features might taint the data set, considering they are not important to the problem at hand.
We can reduce the number of features by using dimensionality reduction techniques:
- Feature Selection
- Feature Extraction
To detect which features are more significant to our data set we can use some strategies:
- Brute force
- Forward Selection
- Backward Selection

# Techniques for Anomaly Detection    
- Classification-based  
	- Neural Networks  
	- Bayesian Networks  
	- Support Vector Machines  
	- Rule-based  
- Nearest neighbour-based  
	- Distance to the k-th Nearest Neighbour  
	- Relative Density  
- Clustering-based  
- Statistical  
	- Parametric  
	- Non parametric  
- Information-theoretical  
- Spectral


# Anomaly Detector Quality of Service

Revisiting now [[DeteçãoETolerância/T2#IDS Quality of Service]], we can take a page out of Machine Learning to evaluate our models and by extension the IDS which make use of them.
In order to visualise the quality of models it is normally employed a confusion matrix, this is a structure that plots Predicted Class vs Real Class.

![[Confusion Matrix.png]]

Moreover we can also use some of the metrics used to evaluate models in Machine Learning
| Metric      | Formula                 |
| ----------- | ----------------------- |
| Error       | $\frac{FP+FN}{n}$       |
| Accuracy    | $\frac{TP+TN}{n}$       |
| TP-rate     | $\frac{TP}{P}$          |
| FP-rate     | $\frac{FP}{N}$          |
| Precision   | $\frac{TP}{p'}$         |
| Recall      | $\frac{TP}{P}$          |
| Sensitivity | $\frac{TP}{P} = Recall$ |
| Specificity            |$\frac{TN}{N}$                         |

# Anomaly-based IDS

Taken all of this into account we can make some new assumptions about Anomaly-based IDSes
Considering that Anomaly-based IDS require some input data to train the model, it isn't true that they are always effective against 0-day attacks
This because, we cannot expect a model that wasn't trained against an attack to be able to detect it.
*Note: semi-supervised (traditional) anomaly detectors could solve the problem (partially), but they tend to have a high error rate!*

Taking this into account we can say that ML IDS are useful because:

They can detect
- Known Attacks
- Similar Attacks to known attacks
- And new attacks that are lead to behaviour completely different from normal behaviour

And cant detect
- New attacks or variation of known attacks
- New services users or variations of normal behaviour

And while there can be some situation where it might be tricky in a nutshell Anomaly-based IDS can do some things that Signature-Based IDSes cant do.

# Summary

Signature-Based IDSes
- Detect attacks based on simple comparison
- Don't detect new attacks
- If they use too many signatures can lead to problems
- There aren't false positives

Anomaly-based IDS
- Estimated error rates usually don't match what is seen in production environments
- Need careful training and validation of models
- Can lead to false negatives and false positives